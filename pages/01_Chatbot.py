"""
Chatbot page for electricity and gas questions.

This page lets users ask energy-related questions and get AI answers using
Groq, keeping the chat history within the Streamlit session state.
"""
from typing import Dict, List

import streamlit as st

from ai_utils import generer_reponse_ia


# Page configuration
st.set_page_config(
    page_title="Chatbot √âlectricit√© & Gaz", 
    page_icon="‚ö°Ô∏è"
)

# Title and short description
st.title("ü§ñ Chatbot √âlectricit√© & Gaz")
st.caption(
    "Questions sur tarifs, index, puissance, taxes, "
    "√©volutions de prix, etc."
)

# Collapsible help: model and creativity guidance
with st.expander("‚ÑπÔ∏è Guide des param√®tres IA"):
    st.markdown("""
    ### ü§ñ Choix du mod√®le IA
    
    **llama-3.1-8b-instant** (par d√©faut)
    - Plus rapide et moins co√ªteux
    - Bonnes r√©ponses pour la plupart des questions
    - Id√©al pour un usage quotidien
    - Excellent pour les questions sur l'√©nergie
    
    **gemma2-9b-it**
    - Mod√®le alternatif de Google
    - Bon pour des r√©ponses cr√©atives
    - Peut donner des perspectives diff√©rentes
    - Utile pour varier les explications
    
    **llama-3.3-70b-versatile**
    - Plus puissant et pr√©cis
    - Meilleur pour des questions complexes et analyses d√©taill√©es
    - Plus lent et plus co√ªteux
    
    üí° **Conseil :** Commencez avec 8b-instant. Passez au 70b si vous avez
    besoin de plus de profondeur/rigueur. Essayez gemma2 pour varier le style.
    
    ### üéöÔ∏è Slider Cr√©ativit√© (Temperature)
    
    **Temperature basse (0.0 - 0.3)** ‚Üê recommand√© pour des r√©ponses fiables
    - R√©ponses plus **pr√©visibles** et **coh√©rentes**
    - L'IA choisit les mots les plus probables
    - Parfait pour des r√©ponses techniques factuelles
    
    **Temperature √©lev√©e (0.7 - 1.0)**
    - R√©ponses plus **cr√©atives** et **vari√©es**
    - L'IA prend plus de "risques" dans le choix des mots
    - Plus de chance d'avoir des explications originales
    
    üí° **Astuce :** Pour des questions √©nergie, gardez 0.2‚Äì0.3 pour la
    pr√©cision; montez √† 0.4‚Äì0.5 si vous voulez plus de cr√©ativit√©.
    """)

# Sidebar with model/temperature controls
with st.sidebar:
    st.subheader("Param√®tres IA")
    
    # Model selection
    modele_choisi = st.selectbox(
        "Mod√®le",
        options=[
            "llama-3.1-8b-instant",
            "gemma2-9b-it",
            "llama-3.3-70b-versatile",
        ],
        index=0,
    )

    # Creativity (temperature)
    temperature = st.slider(
        "Cr√©ativit√© (temperature)", 
        0.0, 
        1.0, 
        0.2, 
        0.05
    )
    
    # Official sources mode (disabled for now)
    mode_sources = False
    
    # Button to clear history
    effacer_historique = st.button("Effacer l'historique")

# Conversation history initialization
cle_historique = "energy_chat_history"
if cle_historique not in st.session_state or effacer_historique:
    st.session_state[cle_historique] = []

# Base system instructions for the assistant
prompt_systeme_base = (
    "Tu es un assistant expert en √©lectricit√© et gaz en France. "
    "R√©ponds en fran√ßais, de mani√®re rigoureuse et actionnable. "
    "Couvre notamment : tarifs r√©glement√©s et offres de march√©, "
    "taxes et contributions (CSPE, CTA, TURPE), puissance souscrite (kVA), "
    "kWh, heures pleines/creuses, index Linky; "
    "pour le gaz : conversion m¬≥‚ÜíkWh (coefficient, PCS/PCI), "
    "zones GRDF, r√©gularisations de facture. "
    "Si la question est ambigu√´, demande des pr√©cisions avant de conclure. "
    "Fournis des √©tapes claires (1,2,3). "
    "Pour toute donn√©e tarifaire susceptible d'√©voluer, "
    "indique la m√©thode de calcul. Ne donne pas de conseils financiers."
)

# Append source citation instructions if enabled
prompt_systeme_final = prompt_systeme_base
if mode_sources:
    prompt_systeme_final += (
        " Cite explicitement au moins une source officielle pertinente "
        "avec un lien court: CRE, Enedis, GRDF, EDF, ENGIE, service‚Äëpublic."
    )

# Render prior messages
for message in st.session_state[cle_historique]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Chat input
question_utilisateur = st.chat_input(
    "Posez votre question (ex: Estimation facture, "
    "heures creuses, index Linky)‚Ä¶"
)

# Handle a new question
if question_utilisateur:
    # Add the user question to history
    st.session_state[cle_historique].append({
        "role": "user", 
        "content": question_utilisateur
    })

    # Generate and show the assistant answer
    with st.chat_message("assistant"):
        with st.spinner("R√©daction de la r√©ponse‚Ä¶"):
            # Get the full history
            historique_complet = st.session_state[cle_historique]
            
            # Adjust temperature if sources mode is active
            if mode_sources:
                temperature_effective = min(temperature, 0.3)
            else:
                temperature_effective = temperature
            
            # Generate the AI response
            reponse = generer_reponse_ia(
                message_utilisateur=None,
                prompt_systeme=prompt_systeme_final,
                messages=historique_complet,
                modele=modele_choisi,
                temperature=temperature_effective,
                tokens_max=800,
                domaine_secours="energy",
            )
            
            # Render the answer
            st.markdown(reponse)
            
            # Append assistant answer to history
            st.session_state[cle_historique].append({
                "role": "assistant", 
                "content": reponse
            })

# Divider and a short tip
st.divider()
st.markdown(
    """
    **Astuce :** pour affiner une estimation, indiquez votre offre, 
    puissance (kVA), consommation annuelle (kWh) et zone.
    """
)


